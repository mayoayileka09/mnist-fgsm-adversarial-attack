{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c9abe2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a266993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "748a36663a3446398c7325b0384d7823",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cc6380d184e44539718d8ace05d8f8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49b88f2b3cb941c18ed05b91f750d906",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1648877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87cb4296e30942ee9818459efa1c5b9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.ToTensor()\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(\n",
    "    root=\"./data\", train=True, download=True, transform=transform\n",
    ")\n",
    "testset = torchvision.datasets.MNIST(\n",
    "    root=\"./data\", train=False, download=True, transform=transform\n",
    ")\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=1000, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58465e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(16*4*4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.max_pool2d(x, 2)\n",
    "\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = torch.max_pool2d(x, 2)\n",
    "\n",
    "        x = x.view(-1, 16*4*4)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe7219aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.2874\n",
      "Epoch [2/10], Loss: 0.0830\n",
      "Epoch [3/10], Loss: 0.0597\n",
      "Epoch [4/10], Loss: 0.0456\n",
      "Epoch [5/10], Loss: 0.0390\n",
      "Epoch [6/10], Loss: 0.0333\n",
      "Epoch [7/10], Loss: 0.0289\n",
      "Epoch [8/10], Loss: 0.0243\n",
      "Epoch [9/10], Loss: 0.0208\n",
      "Epoch [10/10], Loss: 0.0170\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = LeNet().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "\n",
    "    for images, labels in trainloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(trainloader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a051901e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean Test Accuracy: 98.97%\n"
     ]
    }
   ],
   "source": [
    "def test_accuracy(model, loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return 100 * correct / total\n",
    "\n",
    "acc = test_accuracy(model, testloader)\n",
    "print(f\"Clean Test Accuracy: {acc:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37f3140",
   "metadata": {},
   "source": [
    "### Adversial Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a608ab6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pgd_attack(model, images, labels,\n",
    "               epsilon=0.3, alpha=0.01, iters=40,\n",
    "               random_start=True):\n",
    "\n",
    "    model.eval()\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "    ori_images = images.clone().detach()\n",
    "\n",
    "    # random start inside epsilon-ball\n",
    "    if random_start:\n",
    "        noise = torch.empty_like(images).uniform_(-epsilon, epsilon)\n",
    "        adv_images = torch.clamp(ori_images + noise, 0, 1).detach()\n",
    "    else:\n",
    "        adv_images = ori_images.clone().detach()\n",
    "\n",
    "    for i in range(iters):\n",
    "        adv_images.requires_grad = True\n",
    "        outputs = model(adv_images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        model.zero_grad()\n",
    "        if adv_images.grad is not None:\n",
    "            adv_images.grad.data.zero_()\n",
    "        loss.backward()\n",
    "\n",
    "        # gradient step\n",
    "        adv_images = adv_images + alpha * adv_images.grad.sign()\n",
    "\n",
    "        # project into epsilon-ball\n",
    "        adv_images = torch.max(torch.min(adv_images, ori_images + epsilon), ori_images - epsilon)\n",
    "\n",
    "        # valid pixel range\n",
    "        adv_images = torch.clamp(adv_images, 0, 1).detach()\n",
    "\n",
    "    return adv_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "937c12cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def evaluate_pgd(model, loader, epsilon=0.3, alpha=0.01, iters=40):\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    clean_correct = 0\n",
    "    adv_correct = 0\n",
    "    flipped = 0\n",
    "\n",
    "    for images, labels in tqdm(loader, desc=\"PGD Evaluation\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        total += labels.size(0)\n",
    "\n",
    "        # clean predictions\n",
    "        with torch.no_grad():\n",
    "            clean_out = model(images)\n",
    "            _, clean_pred = clean_out.max(1)\n",
    "            clean_correct += (clean_pred == labels).sum().item()\n",
    "\n",
    "        # adversarial examples\n",
    "        adv_images = pgd_attack(model, images, labels,\n",
    "                                epsilon=epsilon, alpha=alpha, iters=iters)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            adv_out = model(adv_images)\n",
    "            _, adv_pred = adv_out.max(1)\n",
    "            adv_correct += (adv_pred == labels).sum().item()\n",
    "\n",
    "        # Attack Success Rate\n",
    "        flipped += ((clean_pred == labels) & (adv_pred != labels)).sum().item()\n",
    "\n",
    "    clean_acc = 100 * clean_correct / total\n",
    "    adv_acc = 100 * adv_correct / total\n",
    "    asr = flipped / clean_correct\n",
    "\n",
    "    return clean_acc, adv_acc, asr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad471480",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PGD Evaluation: 100%|██████████| 10/10 [01:36<00:00,  9.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean Accuracy: 98.97\n",
      "Adversarial Accuracy: 0.01\n",
      "Attack Success Rate (ASR): 0.99989895928059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "clean_acc, adv_acc, asr = evaluate_pgd(model, testloader)\n",
    "print(\"Clean Accuracy:\", clean_acc)\n",
    "print(\"Adversarial Accuracy:\", adv_acc)\n",
    "print(\"Attack Success Rate (ASR):\", asr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
